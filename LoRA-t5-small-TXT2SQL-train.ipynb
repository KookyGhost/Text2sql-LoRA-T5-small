{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9494ada0-1c0e-4abf-9288-1a09a088fe20",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.3)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38073d67-cefd-4e59-9e88-286df90a3f38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 15:15:14.814900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-21 15:15:14.814953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-21 15:15:14.816575: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 15:15:14.824509: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-21 15:15:16.298606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, load_from_disk\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, pipeline\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_int8_training, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ca0f59-c55f-414f-9a5e-19d846851007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a727ceecdc54a849c83570b5976cd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92ea41e1e0149b4996c749329bee3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6dc62edaac4dc08e69eeed3b11b2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03147974a494d7fb00397d6ffcdd75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980e19a2b9474f64a77661d02aec308c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceddf2c118004e3b8eb850e8c977fef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='t5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad16028-35c6-4153-920a-098e187cbcb9",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c37ebe-672e-4b5e-8d23-545dbfb6f251",
   "metadata": {},
   "source": [
    "Combining 3 datasets by renaming the columns and then split into train-val-test set by 8:1:1"
   ]
  },
  {
   "cell_type": "code",
   "id": "e2eba389-1b84-4559-b3f0-cd8b8d254edc",
   "metadata": {
    "tags": []
   },
   "source": [
    "try:\n",
    "    dataset = load_from_disk(\"merged_dataset\")\n",
    "    print(\"Loaded Merged Dataset\")\n",
    "except:\n",
    "    dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]')\n",
    "    dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]')\n",
    "    dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]')\n",
    "\n",
    "    dataset_tts_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:80%]')\n",
    "    dataset_tts_train = dataset_tts_train.remove_columns(['source', 'text'])\n",
    "    dataset_tts_train = dataset_tts_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "    dataset_tts_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-20%:-10%]')\n",
    "    dataset_tts_test  = dataset_tts_test.remove_columns(['source', 'text'])\n",
    "    dataset_tts_test  = dataset_tts_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "    dataset_tts_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-10%:]')\n",
    "    dataset_tts_val   = dataset_tts_val.remove_columns(['source', 'text'])\n",
    "    dataset_tts_val   = dataset_tts_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "    dataset_ks_train  = load_dataset(\"knowrohit07/know_sql\", split='validation[:80%]')\n",
    "    dataset_ks_test   = load_dataset(\"knowrohit07/know_sql\", split='validation[-20%:-10%]')\n",
    "    dataset_ks_val    = load_dataset(\"knowrohit07/know_sql\", split='validation[-10%:]')\n",
    "\n",
    "    dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train, dataset_tts_train, dataset_ks_train]),\n",
    "                            'test': interleave_datasets([dataset_scc_test, dataset_tts_test, dataset_ks_test]),\n",
    "                            'validation': interleave_datasets([dataset_scc_val, dataset_tts_val, dataset_ks_val])})\n",
    "\n",
    "    dataset.save_to_disk(\"merged_dataset\")\n",
    "    print(\"Merged and Saved Dataset\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f965504-afc2-41d5-a9fa-e189a6237a41",
   "metadata": {},
   "source": [
    "# Preprocess the Datasets\n",
    "\n",
    "Tokenization + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bb1662-c429-4d7e-a434-b40d50e770bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = \"Tables:\\n\"\n",
    "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
    "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
    "  \n",
    "    data_zip = zip(example['context'], example['question'])\n",
    "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n",
    "\n",
    "    # Tokenize input (context + question)\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding = True\n",
    "    )\n",
    "\n",
    "    # Tokenize output (answer)\n",
    "    labels = tokenizer(\n",
    "        example['answer'], \n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding = True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels[\"input_ids\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20387e6c-a748-4a89-8c40-28d72a880782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Tokenized Dataset\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tokenized_datasets = load_from_disk(\"tokenized_datasets\")\n",
    "    print(\"Loaded Tokenized Dataset\")\n",
    "except:\n",
    "    tokenized_datasets = dataset.map(\n",
    "                                    tokenize_function,\n",
    "                                    batched=True,  \n",
    "                                    remove_columns=['question', 'context', 'answer'],  # Remove original text fields\n",
    "                                    load_from_cache_file=False,\n",
    "                                    desc=\"Tokenizing dataset\",\n",
    "                                )\n",
    "    \n",
    "    tokenized_datasets.save_to_disk(\"tokenized_datasets\")\n",
    "    print(\"Tokenized and Saved Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc3676e-f885-4d03-8688-07be4228f8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(tokenized_datasets.keys())\n",
    "# print(tokenized_datasets['train'][0].keys())\n",
    "# print(tokenized_datasets['train'][0]['input_ids'])\n",
    "# print(tokenized_datasets['train'][0]['labels'])\n",
    "# print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01bc23b-f52f-4617-b64e-20e9e6397879",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configure LoRA adapter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864db7dc-9d4f-4aca-abab-1abc1ead9d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    # target_modules=[\"q\", \"v\", \"o\", \"wi_0\", \"wi_1\", \"wo\"],\n",
    "    # modules_to_save=[\"lm_head\", \"embed_tokens\"],\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334b0a12-411c-4bbc-97a7-5af7542aa963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name='t5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b754d91-7a13-42af-8358-472e265fc889",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850403779272945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/utils/other.py:136: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bab8f4-2805-4256-91e6-f158818ec18c",
   "metadata": {},
   "source": [
    "# Finetuning LoRA adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "621e8e44-43ed-407c-a081-1622471291b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "label_pad_token_id = -100\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7182139-b2f4-4c64-bd35-01ec5b09849f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = f'tunes/sql-training-{str(int(time.time()))}'\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=5e-3,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    per_device_train_batch_size=16,     # batch size per device during training\n",
    "    per_device_eval_batch_size=16,      # batch size for evaluation\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"steps\",\n",
    "    label_names = ['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf9b8c0-a555-46a9-84d9-ec5560f6d1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 118695\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef268ff5-92f7-4ba2-8e6c-41880b5bd665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-21 00:11:49,383] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0c79b9-1e99-4c31-97b6-47d998eba6b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkookyghost\u001b[0m (\u001b[33mkookyghost-university-of-connecticut\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20250321_001152-wpd8zwz4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4' target=\"_blank\">tunes/sql-training-1742515904</a></strong> to <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface' target=\"_blank\">https://wandb.ai/kookyghost-university-of-connecticut/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4' target=\"_blank\">https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14838' max='14838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14838/14838 2:21:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.189200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.055800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.043300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14838, training_loss=0.05259703612902814, metrics={'train_runtime': 8471.1663, 'train_samples_per_second': 28.023, 'train_steps_per_second': 1.752, 'total_flos': 3.234385838997504e+16, 'train_loss': 0.05259703612902814, 'epoch': 2.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f841a730f90, execution_count=18 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f8419af2fd0, raw_cell=\"model.config.use_cache = False\n",
      "\n",
      "trainer.train()\" store_history=True silent=False shell_futures=True cell_id=bc0c79b9-1e99-4c31-97b6-47d998eba6b9> result=TrainOutput(global_step=14838, training_loss=0.05259703612902814, metrics={'train_runtime': 8471.1663, 'train_samples_per_second': 28.023, 'train_steps_per_second': 1.752, 'total_flos': 3.234385838997504e+16, 'train_loss': 0.05259703612902814, 'epoch': 2.0})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5984074-f909-4f96-9ff1-0d2c7d44a6e5",
   "metadata": {},
   "source": [
    "# Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea600991-24a2-47aa-8ac3-a1c3673c5b5f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f83bc691310, raw_cell=\"trainer.model.save_pretrained('tuned_model')\n",
      "token..\" store_history=True silent=False shell_futures=True cell_id=ea600991-24a2-47aa-8ac3-a1c3673c5b5f>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('tuned_model/tokenizer_config.json',\n",
       " 'tuned_model/special_tokens_map.json',\n",
       " 'tuned_model/spiece.model',\n",
       " 'tuned_model/added_tokens.json',\n",
       " 'tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f83bc406950, execution_count=20 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f83bc691310, raw_cell=\"trainer.model.save_pretrained('tuned_model')\n",
      "token..\" store_history=True silent=False shell_futures=True cell_id=ea600991-24a2-47aa-8ac3-a1c3673c5b5f> result=('tuned_model/tokenizer_config.json', 'tuned_model/special_tokens_map.json', 'tuned_model/spiece.model', 'tuned_model/added_tokens.json', 'tuned_model/tokenizer.json')>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.model.save_pretrained('tuned_model')\n",
    "tokenizer.save_pretrained('tuned_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cce07-8dbe-4699-8104-3b56fb1c1a23",
   "metadata": {},
   "source": [
    "# Compare Parameter Numbers between Base Model and LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca4c8f13-8107-474d-bac9-8da35beabd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff528575-808f-476a-a8dc-fdaba52138f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_model_size(path):\n",
    "    size = 0\n",
    "    for f in os.scandir(path):\n",
    "        size += os.path.getsize(f)\n",
    "\n",
    "    print(f\"Model size: {(size / 1e6):.2} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daffd9a1-4050-447e-94cc-49e042a75cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model, label):\n",
    "    parameters, trainable = 0, 0\n",
    "    \n",
    "    for _, p in model.named_parameters():\n",
    "        parameters += p.numel()\n",
    "        trainable += p.numel() if p.requires_grad else 0\n",
    "\n",
    "    print(f\"{label} trainable parameters: {trainable:,}/{parameters:,} ({100 * trainable / parameters:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "028a8b92-1a45-4ad7-bf31-5ab5ce3a00ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75072719f68843d09691ca5f3dcd8a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bf4e24583b438588f1fe91d14d2715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65b204d1a104d6e95d066187dfb9eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1855dffb71e44d7f80b0bbb3cafca0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e098733b2f94ca78c9efd94da4675c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3c09baf4a143ecae62d850ad06e382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='t5-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "original_model = original_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6176be1-5719-4044-a746-6cb3c603257d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model trainable parameters: 60,506,624/60,506,624 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(original_model,'base model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5a85d5-0c19-4030-b091-aca2719ba557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(original_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefc9180-176e-4b35-83fa-0a2b3aa19537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA model trainable parameters: 294,912/60,801,536 (0.49%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model,'LoRA model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ca181f-b343-4815-b73c-194b8a2370d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "print_model_size('tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fd1a81e-7f63-4ac3-9bdd-85e17cb75279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model('tuned_model_save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8889f92d-469d-4a26-b9b7-db3d9651d9e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f841a629410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f83d2246b90, raw_cell=\"import wandb\n",
      "wandb.finish()\n",
      "# wandb.login()  \" store_history=True silent=False shell_futures=True cell_id=8889f92d-469d-4a26-b9b7-db3d9651d9e8>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▆▅▄▅▃▂█▃▇▄▃▂▁▂▃▂▃▂▁▄▆▂▂▃▁▂▂▂▂</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3.234385838997504e+16</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>14838</td></tr><tr><td>train/grad_norm</td><td>0.0454</td></tr><tr><td>train/learning_rate</td><td>0.00011</td></tr><tr><td>train/loss</td><td>0.0322</td></tr><tr><td>train_loss</td><td>0.0526</td></tr><tr><td>train_runtime</td><td>8471.1663</td></tr><tr><td>train_samples_per_second</td><td>28.023</td></tr><tr><td>train_steps_per_second</td><td>1.752</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tunes/sql-training-1742515904</strong> at: <a href='https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4' target=\"_blank\">https://wandb.ai/kookyghost-university-of-connecticut/huggingface/runs/wpd8zwz4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250321_001152-wpd8zwz4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()\n",
    "# wandb.login()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
